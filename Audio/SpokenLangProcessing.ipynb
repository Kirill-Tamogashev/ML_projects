{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of homework audio.ipynb","provenance":[{"file_id":"1ksCh860-sfEDzYxpXqXOw11G7IKE5T3v","timestamp":1622108278255}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1e21443d140e4e6f8c55c77145254876":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_af68a66cec6447ae9e872bcaad39535b","IPY_MODEL_62f1f6f32ff54df4950797eba4681b91"],"layout":"IPY_MODEL_88c712760669489c9e9b1b3b8260dadd"}},"af68a66cec6447ae9e872bcaad39535b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":" 37%","description_tooltip":null,"layout":"IPY_MODEL_6f44a005ffdf4c96b00c7c260f11933c","max":1500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e14f56c07cf4a8cb0f942c9b7401960","value":551}},"62f1f6f32ff54df4950797eba4681b91":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0938add5aca94c5ab4816be99264cfed","placeholder":"​","style":"IPY_MODEL_3da9ecf359f9407686ecb62483a9d0b0","value":" 551/1500 [01:06&lt;02:25,  6.51it/s]"}},"88c712760669489c9e9b1b3b8260dadd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f44a005ffdf4c96b00c7c260f11933c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e14f56c07cf4a8cb0f942c9b7401960":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"0938add5aca94c5ab4816be99264cfed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3da9ecf359f9407686ecb62483a9d0b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"149d3683d6374e18ab9bf727ed154cb2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e82bbe679c1646009ab4063678cad694","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e8d2133aabcb49599acf8fc30e615ec5","IPY_MODEL_186976089fb94e3ba54dcc6684cca041"]}},"e82bbe679c1646009ab4063678cad694":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e8d2133aabcb49599acf8fc30e615ec5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_403daf587fb441fe9bae050e8ff831f1","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":500,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":500,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ca55bfadc1eb4665ac8ae9a4d194e62d"}},"186976089fb94e3ba54dcc6684cca041":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2a4730004913480780fa30fca8539d4a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 500/500 [02:34&lt;00:00,  3.24it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7101e1c66aad472da7b3fdd2b430d31b"}},"403daf587fb441fe9bae050e8ff831f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ca55bfadc1eb4665ac8ae9a4d194e62d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2a4730004913480780fa30fca8539d4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7101e1c66aad472da7b3fdd2b430d31b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d4e0bd88bc824474a4efbcbb10b87319":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_dc91d82e92744fa5959cba673a8000fc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_03e96ed9d9df4575bb57a429ad4e5d5b","IPY_MODEL_32e91f01718443d3891be6486168643b"]}},"dc91d82e92744fa5959cba673a8000fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"03e96ed9d9df4575bb57a429ad4e5d5b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fd9b8c62ab0c42d9b4dd6d0ed206efc0","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e6ce1fd210b84d63bcc81636535b76d7"}},"32e91f01718443d3891be6486168643b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_96636997635e48e3b3ec69ae2e3dbabf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1000/1000 [02:37&lt;00:00,  6.34it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_01e29c3dd59b4709b7266f378538b7b5"}},"fd9b8c62ab0c42d9b4dd6d0ed206efc0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e6ce1fd210b84d63bcc81636535b76d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"96636997635e48e3b3ec69ae2e3dbabf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"01e29c3dd59b4709b7266f378538b7b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"abb690c9602c41ca885fb0690b6c64ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2827e057c7a0417d9540ddc9774fdaec","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_15d40502a48b4d36bffc779ef8407d88","IPY_MODEL_72e775b2e1f84ed297f028c43b29b9b7"]}},"2827e057c7a0417d9540ddc9774fdaec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"15d40502a48b4d36bffc779ef8407d88":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ae52c24d1efa415ba76fdbe6eb3a2064","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":800,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":800,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8f66589297d34c3cbcaf6620dd02fad9"}},"72e775b2e1f84ed297f028c43b29b9b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1b5917171abe41d18facf723c8d38d0d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 800/800 [05:53&lt;00:00,  2.26it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_11d946060b1e494aacba6ec540353d28"}},"ae52c24d1efa415ba76fdbe6eb3a2064":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8f66589297d34c3cbcaf6620dd02fad9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1b5917171abe41d18facf723c8d38d0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"11d946060b1e494aacba6ec540353d28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"zahzrEdRCaxV"},"source":["### Spoken Language Processing\n","В этом задании предлагается обучить классификатор класса возраста по голосу (пример с тем, как это можно сделать для пола см. в семинаре)\n","\n","Подумайте, как лучше предсказывать возраст (может быть разбить на группы?) и какой лосс использовать\n","\n","P.S. не забудьте, что если то вы работает в Colab, то вы можете поменять среду выполнения на GPU/TPU!\n","\n","Вопросы по заданию/материалам: @Nestyme"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3wSgHrbiEc8x","executionInfo":{"status":"ok","timestamp":1622403571480,"user_tz":-180,"elapsed":42617,"user":{"displayName":"Кирилл Тамогашев","photoUrl":"","userId":"04444979527243233763"}},"outputId":"0929206f-9dbc-432a-ffe8-285d9f9afe97"},"source":["!pip3 install -q timit-utils==0.9.0\n","!pip3 install -q torchaudio\n","!wget https://ndownloader.figshare.com/files/10256148 \n","!unzip -q 10256148"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 1.9MB 30.1MB/s \n","\u001b[?25h--2021-05-30 19:38:55--  https://ndownloader.figshare.com/files/10256148\n","Resolving ndownloader.figshare.com (ndownloader.figshare.com)... 34.241.102.62, 52.212.10.43, 176.34.153.62, ...\n","Connecting to ndownloader.figshare.com (ndownloader.figshare.com)|34.241.102.62|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/10256148/TIMIT.zip [following]\n","--2021-05-30 19:38:55--  https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/10256148/TIMIT.zip\n","Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.62.163\n","Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.62.163|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 440207227 (420M) [binary/octet-stream]\n","Saving to: ‘10256148’\n","\n","10256148            100%[===================>] 419.81M  7.35MB/s    in 26s     \n","\n","2021-05-30 19:39:22 (15.9 MB/s) - ‘10256148’ saved [440207227/440207227]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u0bovLZ0Ew5V"},"source":["import timit_utils as tu\n","import os\n","import librosa\n","import numpy as np\n","from tqdm.notebook import tqdm\n","\n","import torch\n","import torch.nn as nn\n","from torch.optim import Adam\n","import torch.nn.functional as F\n","\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score\n","\n","import IPython\n","_TIMIT_PATH = 'data/lisa/data/timit/raw/TIMIT'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dP2VdDlaAHwP","executionInfo":{"status":"ok","timestamp":1622404205017,"user_tz":-180,"elapsed":207,"user":{"displayName":"Кирилл Тамогашев","photoUrl":"","userId":"04444979527243233763"}},"outputId":"f161f1fe-baa5-446a-dd2e-9e3e849e17d7"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sun May 30 19:50:04 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   63C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gd-qfC9-DdnJ"},"source":["## Задание 1\n","Загрузите данные для обучения. Для этого:\n","1. Скачайте датасет TIMIT (см семинар)\n","2. Соберите пары \"голос\"  — \"класс возраста\" также, как на семинаре собирались пары \"голос\"  — \"пол\". Аудиодорожки сконвертируйте в мелспектрограммы при помощи `torchaudio либо` `librosa`\n","\n","P.S. вы можете использовать свою реализацию, а можете предложенную (см следующие ячейки)"]},{"cell_type":"code","metadata":{"id":"DhPyP4T5DdAD"},"source":["import timit_utils as tu\n","import os\n","import librosa\n","import numpy as np\n","from tqdm import tqdm\n","\n","import torch as t\n","\n","\n","class timit_dataloader:\n","    def __init__(self, data_path=_TIMIT_PATH, train_mode=True, age_mode=True):\n","        self.doc_file_path = os.path.join(data_path, 'DOC', 'SPKRINFO.TXT')\n","        self.corpus = tu.Corpus(data_path)\n","        with open(self.doc_file_path) as f:\n","            self.id_age_dict = dict(\n","                [(tmp.split(' ')[0], 86 - int(tmp.split('  ')[5].split('/')[-1].replace('??', '50'))) \\\n","                 for tmp in f.readlines()[39:]])\n","        if train_mode:\n","            self.trainset = self.create_dataset('train', age_mode=age_mode)\n","            self.validset = self.create_dataset('valid', age_mode=age_mode)\n","        self.testset = self.create_dataset('test', age_mode=age_mode)\n","\n","    def return_age(self, id):\n","        return self.id_age_dict[id]\n","\n","    def return_data(self):\n","        return self.trainset, self.validset, self.testset\n","\n","    def return_test(self):\n","        return self.testset\n","\n","    def create_dataset(self, mode, age_mode=False):\n","        global people\n","        assert mode in ['train', 'valid', 'test']\n","        if mode == 'train':\n","            people = [self.corpus.train.person_by_index(i) for i in range(350)]\n","        if mode == 'valid':\n","            people = [self.corpus.train.person_by_index(i) for i in range(350, 400)]\n","        if mode == 'test':\n","            people = [self.corpus.test.person_by_index(i) for i in range(150)]\n","        spectrograms_and_targets = []\n","        for person in tqdm(people):\n","              try:\n","                  target = self.return_age(person.name)\n","                  for i in range(len(person.sentences)):\n","                      spectrograms_and_targets.append(\n","                          self.preprocess_sample(person.sentence_by_index(i).raw_audio, target, age_mode=True))\n","              except:\n","                  print(person.name, target)\n","\n","        X, y = map(np.stack, zip(*spectrograms_and_targets))\n","        X = X.transpose([0, 2, 1])  # to [batch, time, channels]\n","        return X, y\n","\n","    @staticmethod\n","    def spec_to_image(spec, eps=1e-6):\n","        mean = spec.mean()\n","        std = spec.std()\n","        spec_norm = (spec - mean) / (std + eps)\n","        spec_min, spec_max = spec_norm.min(), spec_norm.max()\n","        spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n","        spec_scaled = spec_scaled.astype(np.uint8)\n","        return spec_scaled\n","\n","    @staticmethod\n","    def clasterize_by_age(age):\n","        if age < 25:\n","            return 0 # 0\n","        if 25 < age < 40:\n","            return 1 # 0.5\n","        if age > 40:\n","            return 2 # 1\n","\n","\n","    # def clasterize_by_age(age):\n","    #     if age < 20:\n","    #         return 0 \n","    #     if 20 < age < 25:\n","    #         return 1\n","    #     if 25 < age < 30:\n","    #         return 2 \n","    #     if age > 30:\n","    #         return 3\n","\n","    def preprocess_sample(self, amplitudes, target, age_mode=False, sr=16000, max_length=150):\n","        spectrogram = librosa.feature.melspectrogram(amplitudes, sr=sr, n_mels=128, fmin=1, fmax=8192)[:, :max_length]\n","        spectrogram = np.pad(spectrogram, [[0, 0], [0, max(0, max_length - spectrogram.shape[1])]], mode='constant')\n","        target = self.clasterize_by_age(target)\n","        return self.spec_to_image(np.float32(spectrogram)), target\n","\n","    def preprocess_sample_inference(self, amplitudes, sr=16000, max_length=150, device='cpu'):\n","        spectrogram = librosa.feature.melspectrogram(amplitudes, sr=sr, n_mels=128, fmin=1, fmax=8192)[:, :max_length]\n","        spectrogram = np.pad(spectrogram, [[0, 0], [0, max(0, max_length - spectrogram.shape[1])]], mode='constant')\n","        spectrogram = np.array([self.spec_to_image(np.float32(spectrogram))]).transpose([0, 2, 1])\n","\n","        return t.tensor(spectrogram, dtype=t.float).to(device, non_blocking=True)\n","\n","\n","class dataloader:\n","    def __init__(self, spectrograms, targets):\n","        self.data = list(zip(spectrograms, targets))\n","\n","    def next_batch(self, batch_size, device):\n","        indices = np.random.randint(len(self.data), size=batch_size)\n","\n","        input = [self.data[i] for i in indices]\n","        \n","        source = []\n","        target = []\n","        for line in input:\n","            if line[0] is not None and line[1] is not None:\n","                source.append(line[0])\n","                target.append(line[1])\n","\n","        return self.torch_batch(source, target, device)\n","\n","    @staticmethod\n","    def torch_batch(source, target, device):\n","        return tuple(\n","            [\n","                t.tensor(val, dtype=t.float).to(device, non_blocking=True)\n","                for val in [source, target] \n","            ]\n","        )\n","\n","    @staticmethod\n","    def padd_sequences(lines, pad_token=0):\n","        lengths = [len(line) for line in lines]\n","        max_length = max(lengths)\n","\n","        return np.array(\n","            [\n","                line + [pad_token] * (max_length - lengths[i])\n","                for i, line in enumerate(lines)\n","            ]\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tpz1Q5VOFxLM"},"source":["Простая сверточная сеть, ее можно дотюнить или поменять по желанию"]},{"cell_type":"code","metadata":{"id":"sLUggB9iF6s_"},"source":["_timit_dataloader = timit_dataloader()\n","train, valid, test = _timit_dataloader.return_data()\n","\n","trainset = dataloader(*train)\n","validset = dataloader(*valid)\n","testset = dataloader(*test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qF9fIVq7Dbwx"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class Model(nn.Module):\n","    def __init__(self, window_sizes=(3, 4, 5)):\n","        super(Model, self).__init__()\n","\n","        self.convs1 = nn.ModuleList([\n","            nn.Conv2d(1, 128, [window_size, 128], padding=(window_size - 1, 0))\n","            for window_size in window_sizes\n","        ])\n","\n","        self.fc = nn.Linear(128 * len(window_sizes), 3)\n","\n","    def forward(self, x):\n","        x = torch.unsqueeze(x, 1)  # [B, 1, T, E] Add a channel dim.\n","        xs = []\n","        for conv1 in self.convs1:\n","\n","            x2 = F.relu(conv1(x)) # [B, F, T, 1]\n","\n","            x2 = torch.squeeze(x2, -1)  # [B, F, T]\n","            x2 = F.max_pool1d(x2, x2.size(2))  # [B, F, 1]\n","            xs.append(x2)\n","\n","        x = torch.cat(xs, 2)  # [B, F, window]\n","\n","        # FC\n","        x = x.view(x.size(0), -1)  # [B, F * window]\n","        logits = self.fc(x)  # [B, class]\n","        probs = torch.sigmoid(logits) #.view(-1)\n","        return probs\n","\n","    def loss(self, probs, targets):\n","        return nn.CrossEntropyLoss()(probs.float(), targets.long())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MBdcxR-F9sf_","executionInfo":{"status":"ok","timestamp":1622404490005,"user_tz":-180,"elapsed":203,"user":{"displayName":"Кирилл Тамогашев","photoUrl":"","userId":"04444979527243233763"}},"outputId":"6cd9c06f-805f-4ec9-a8dc-cf821eb5f3e7"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'using {device} mode')\n","patience = 500\n","best_loss = 1000\n","cnt = 0\n","BATCH_SIZE = 64"],"execution_count":null,"outputs":[{"output_type":"stream","text":["using cuda mode\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hkj-_KuP8YdE"},"source":["model = Model()\n","if device == torch.device('cuda'):\n","    model.cuda()\n","else:\n","    model.cpu()\n","model.train()\n","\n","optimizer = Adam(\n","    [p for p in model.parameters() if p.requires_grad], betas=(0.9, 0.999), eps=1e-5\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bDlWSdtF0Be1"},"source":["input, target = trainset.next_batch(64, device)\n","out = model(input)\n","model.loss(out, target).item()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ScCZEMvXHkmz"},"source":["#Задание 2\n","1. Обучите свой классификатор категории возраста\n","2. Попробуйте улучшить результат. Можно попробовать усложнить сетку, подвигать границы категорий, поискать новые данные, что угодно, кроме учиться на тесте :)\n","3. Какой подход оказался самым эффективным? Как думаете, почему?\n","4. Как считаете, где можно было бы применить такой классификатор в качестве вспомогательной задачи?\n"]},{"cell_type":"markdown","metadata":{"id":"N7ZAL7ic9c9T"},"source":["Сначала используем Baseline модель и оценим ее качество"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"16oAQfQX-8pC","executionInfo":{"elapsed":200,"status":"ok","timestamp":1622306800482,"user":{"displayName":"Кирилл Тамогашев","photoUrl":"","userId":"04444979527243233763"},"user_tz":-180},"outputId":"6707cab5-e1ae-41c5-a14f-0197e1e40330"},"source":["model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Model(\n","  (convs1): ModuleList(\n","    (0): Conv2d(1, 128, kernel_size=[3, 128], stride=(1, 1), padding=(2, 0))\n","    (1): Conv2d(1, 128, kernel_size=[4, 128], stride=(1, 1), padding=(3, 0))\n","    (2): Conv2d(1, 128, kernel_size=[5, 128], stride=(1, 1), padding=(4, 0))\n","  )\n","  (fc): Linear(in_features=384, out_features=3, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":160}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":678,"referenced_widgets":["1e21443d140e4e6f8c55c77145254876","af68a66cec6447ae9e872bcaad39535b","62f1f6f32ff54df4950797eba4681b91","88c712760669489c9e9b1b3b8260dadd","6f44a005ffdf4c96b00c7c260f11933c","1e14f56c07cf4a8cb0f942c9b7401960","0938add5aca94c5ab4816be99264cfed","3da9ecf359f9407686ecb62483a9d0b0"]},"id":"WoqxAskk8Wtc","executionInfo":{"elapsed":66479,"status":"ok","timestamp":1622306869053,"user":{"displayName":"Кирилл Тамогашев","photoUrl":"","userId":"04444979527243233763"},"user_tz":-180},"outputId":"af65ebcf-5df5-439c-f4a7-c759bde596ad"},"source":["from tqdm.notebook  import tqdm\n","import torch as t\n","\n","\n","for i in tqdm(range(1500)):\n","\n","    optimizer.zero_grad()\n","\n","    input, target = trainset.next_batch(BATCH_SIZE, device=device)\n","    out = model(input)\n","    loss = model.loss(out, target)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if i % 50 == 0:\n","        model.eval()\n","\n","        with torch.no_grad():\n","            optimizer.zero_grad()\n","\n","            input, target = validset.next_batch(BATCH_SIZE, device=device)\n","            out = model(input)\n","            valid_loss = model.loss(out, target)\n","            out, target = out.cpu().detach(), target.cpu().detach()\n","            # print(out, target)\n","            #out = [1 if tmp > 0.5 else 0 for tmp in out]\n","            # print(target)\n","            # print('------')\n","            # print(out)\n","            pred_class = torch.argmax(out, axis=1)\n","            print(f'accuracy_score:{accuracy_score(pred_class, target.long())}')\n","            print(\"i {}, valid {}\".format(i, valid_loss.item()))\n","            print(\"_________\")\n","\n","        model.train()\n","\n","    if i % 50 == 0 and best_loss > valid_loss.item():\n","        best_loss = valid_loss.item()\n","        cnt = 0\n","    else:\n","        cnt += 1\n","\n","    if cnt > patience:\n","        break\n","print('training finished')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e21443d140e4e6f8c55c77145254876","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1500.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["accuracy_score:0.5535714285714286\n","i 0, valid 0.9985033869743347\n","_________\n","accuracy_score:0.7692307692307693\n","i 50, valid 0.7822141051292419\n","_________\n","accuracy_score:0.6842105263157895\n","i 100, valid 0.8672343492507935\n","_________\n","accuracy_score:0.5862068965517241\n","i 150, valid 0.9652380347251892\n","_________\n","accuracy_score:0.7450980392156863\n","i 200, valid 0.8063468933105469\n","_________\n","accuracy_score:0.6530612244897959\n","i 250, valid 0.8983836770057678\n","_________\n","accuracy_score:0.625\n","i 300, valid 0.926444947719574\n","_________\n","accuracy_score:0.6071428571428571\n","i 350, valid 0.9443020820617676\n","_________\n","accuracy_score:0.6666666666666666\n","i 400, valid 0.8847782015800476\n","_________\n","accuracy_score:0.6326530612244898\n","i 450, valid 0.9187917709350586\n","_________\n","accuracy_score:0.6037735849056604\n","i 500, valid 0.9476713538169861\n","_________\n","accuracy_score:0.6379310344827587\n","i 550, valid 0.9135138392448425\n","_________\n","training finished\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GNfHqRcX9haD","executionInfo":{"elapsed":2558,"status":"ok","timestamp":1622306921035,"user":{"displayName":"Кирилл Тамогашев","photoUrl":"","userId":"04444979527243233763"},"user_tz":-180},"outputId":"15c30277-e201-4001-85f2-f673c7338a43"},"source":["model.eval()\n","\n","with torch.no_grad():\n","    optimizer.zero_grad()\n","    acc_list = []\n","    for _ in range(20):\n","        input, target = testset.next_batch(BATCH_SIZE, device=device)\n","        out = model(input)\n","        valid_loss = model.loss(out, target)\n","        out, target = out.cpu().detach(), target.cpu().detach()\n","\n","        pred_class = torch.argmax(out, axis=1)\n","        score = accuracy_score(pred_class, target.long())\n","        acc_list.append(score)\n","print('Mean accuracy score {:.3}'.format(np.mean(acc_list)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mean accuracy score 0.698\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"omF43Vw1uQsC"},"source":["Это baseline результат. Теперь создадим собственную модель и улучшим результат "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T-UliYomADm-","executionInfo":{"elapsed":216,"status":"ok","timestamp":1622306478257,"user":{"displayName":"Кирилл Тамогашев","photoUrl":"","userId":"04444979527243233763"},"user_tz":-180},"outputId":"13799ada-3fd3-4ac1-d1d6-b6b01888e94f"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sat May 29 16:41:18 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   78C    P0    33W /  70W |   2458MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aOzMi8GZynOg"},"source":["1) Теперь попытаемся увеличить качество, изменив количество параметров. Добавим еще три сверочных слоя. Проверим, получится ли у сетки в таком случае отискивать более сложные закономероности, что могло бы позволить улучшить качество."]},{"cell_type":"code","metadata":{"id":"ugJrGQ003V65"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class NewModel(nn.Module):\n","    def __init__(self, window_sizes=(3, 4, 4)):\n","        super(NewModel, self).__init__()\n","\n","        self.convs1 = nn.ModuleList([\n","            nn.Conv2d(1, 128, [window_size, 128], padding=(window_size - 1, 0))\n","            for window_size in window_sizes\n","        ])\n","\n","        self.convs2 = nn.ModuleList([\n","            nn.Conv2d(1, 128, [window_size, 128], padding=(window_size - 1, 0))\n","            for window_size in window_sizes\n","        ])\n","\n","        self.convs3 = nn.ModuleList([\n","            nn.Conv2d(1, 128, [window_size, 128], padding=(window_size - 1, 0))\n","            for window_size in window_sizes\n","        ])\n","        self.batchnorm128 = nn.BatchNorm2d(128)\n","        self.batchnorm64 = nn.BatchNorm2d(64)\n","        self.batchnorm32 = nn.BatchNorm2d(32)\n","        self.fc = nn.Linear(128 * len(window_sizes), 4)\n","\n","    def forward(self, x):\n","        x = torch.unsqueeze(x, 1)  # [B, 1, T, E] Add a channel dim.\n","        xs = []\n","        for conv1, conv2, conv3 in zip(self.convs1, self.convs2, self.convs3):\n","\n","            # print(x.shape)\n","            x2 = F.relu(conv1(x)) # [B, F, T, 1]\n","            x2 = self.batchnorm128(x2)\n","            # print(x2.permute(0, 3, 2, 1).shape)\n","\n","            x2 =  F.relu(conv2(x2.permute(0, 3, 2, 1)))\n","            x2 = self.batchnorm128(x2)\n","            # print(x2.shape)\n","\n","            x2 =  F.relu(conv3(x2.permute(0, 3, 2, 1)))\n","            x2 = self.batchnorm128(x2)\n","\n","            x2 = torch.squeeze(x2, -1)  # [B, F, T]\n","            x2 = F.max_pool1d(x2, x2.size(2))  # [B, F, 1]\n","            xs.append(x2)\n","            \n","        x = torch.cat(xs, 2)  # [B, F, window]\n","\n","\n","        # FC\n","        x = x.view(x.size(0), -1)  # [B, F * window]\n","        logits = self.fc(x)  # [B, class]\n","        probs = torch.sigmoid(logits) #.view(-1)\n","        return probs\n","\n","    def loss(self, probs, targets):\n","        return nn.CrossEntropyLoss()(probs.float(), targets.long())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GCsXLgBe3YuH"},"source":["model = NewModel()\n","if device == torch.device('cuda'):\n","    model.cuda()\n","else:\n","    model.cpu()\n","model.train()\n","\n","patience = 1000\n","best_loss = 1000\n","cnt = 0\n","BATCH_SIZE = 64"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XCuQE6LU3bOA","executionInfo":{"status":"ok","timestamp":1622405982248,"user_tz":-180,"elapsed":200,"user":{"displayName":"Кирилл Тамогашев","photoUrl":"","userId":"04444979527243233763"}},"outputId":"ac4ac8ab-dc49-4633-ac27-92157431ad64"},"source":["input, target = trainset.next_batch(64, device)\n","out = model(input)\n","model.loss(out, target).item()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.3886786699295044"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":338,"referenced_widgets":["149d3683d6374e18ab9bf727ed154cb2","e82bbe679c1646009ab4063678cad694","e8d2133aabcb49599acf8fc30e615ec5","186976089fb94e3ba54dcc6684cca041","403daf587fb441fe9bae050e8ff831f1","ca55bfadc1eb4665ac8ae9a4d194e62d","2a4730004913480780fa30fca8539d4a","7101e1c66aad472da7b3fdd2b430d31b"]},"id":"4azc5A4T3kpo","executionInfo":{"status":"ok","timestamp":1622406331919,"user_tz":-180,"elapsed":61177,"user":{"displayName":"Кирилл Тамогашев","photoUrl":"","userId":"04444979527243233763"}},"outputId":"9ae899c2-ff2e-4143-fc31-8ca5a2512ecd"},"source":["from tqdm.notebook  import tqdm\n","import torch as t\n","\n","optimizer = Adam(\n","    [p for p in model.parameters() if p.requires_grad], lr=1e-3, betas=(0.9, 0.999), eps=1e-5\n",")\n","\n","for i in tqdm(range(500)):\n","\n","    optimizer.zero_grad()\n","\n","    input, target = trainset.next_batch(BATCH_SIZE, device=device)\n","    out = model(input)\n","    loss = model.loss(out, target)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if i % 100 == 0:\n","        model.eval()\n","\n","        with torch.no_grad():\n","            optimizer.zero_grad()\n","\n","            input, target = validset.next_batch(BATCH_SIZE, device=device)\n","            out = model(input)\n","            valid_loss = model.loss(out, target)\n","            out, target = out.cpu().detach(), target.cpu().detach()\n","\n","            pred_class = torch.argmax(out, axis=1)\n","            print(f'accuracy_score:{accuracy_score(pred_class, target.long())}')\n","            print(\"i {}, valid {}\".format(i, valid_loss.item()))\n","            print(\"_________\")\n","\n","        model.train()\n","\n","    if i % 1000 == 0 and best_loss > valid_loss.item():\n","        best_loss = valid_loss.item()\n","        cnt = 0\n","    else:\n","        cnt += 1\n","\n","    if cnt > patience:\n","        break\n","print('training finished')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"149d3683d6374e18ab9bf727ed154cb2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["accuracy_score:0.6938775510204082\n","i 0, valid 1.0943212509155273\n","_________\n","accuracy_score:0.6833333333333333\n","i 100, valid 1.0557618141174316\n","_________\n","accuracy_score:0.6\n","i 200, valid 1.1277204751968384\n","_________\n","accuracy_score:0.7659574468085106\n","i 300, valid 0.9621021747589111\n","_________\n","accuracy_score:0.6122448979591837\n","i 400, valid 1.1225416660308838\n","_________\n","\n","training finished\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nwb1g-XL7YQq","executionInfo":{"status":"ok","timestamp":1622406355169,"user_tz":-180,"elapsed":2653,"user":{"displayName":"Кирилл Тамогашев","photoUrl":"","userId":"04444979527243233763"}},"outputId":"b55b0409-ebee-418c-89bf-8dd3fa664fec"},"source":["model.eval()\n","\n","with torch.no_grad():\n","    optimizer.zero_grad()\n","    acc_list = []\n","    for _ in range(20):\n","        input, target = testset.next_batch(BATCH_SIZE, device=device)\n","        out = model(input)\n","        valid_loss = model.loss(out, target)\n","        out, target = out.cpu().detach(), target.cpu().detach()\n","\n","        pred_class = torch.argmax(out, axis=1)\n","        score = accuracy_score(pred_class, target.long())\n","        acc_list.append(score)\n","print('Mean accuracy score {:.3}'.format(np.mean(acc_list)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mean accuracy score 0.693\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-P3yLfNR3n-r"},"source":["Качесто осталось примеро таким же, то есть увеличение параметров не дало прирост в результатах.\n","\n","2) Теперь попытаемся увеличить качество, изменив количество классов до 4. То есть мы сделаем разбиение возрастов более подробным. (для этого слегка изменим исходную функцию сосздания датасетов и и заново создадим даталоадеры)\n"]},{"cell_type":"code","metadata":{"id":"TvuOBH18uEX6"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class NewModel(nn.Module):\n","    def __init__(self, window_sizes=(3, 4, 4)):\n","        super(NewModel, self).__init__()\n","\n","        self.convs1 = nn.ModuleList([\n","            nn.Conv2d(1, 128, [window_size, 128], padding=(window_size - 1, 0))\n","            for window_size in window_sizes\n","        ])\n","\n","        self.convs2 = nn.ModuleList([\n","            nn.Conv2d(1, 128, [window_size, 128], padding=(window_size - 1, 0))\n","            for window_size in window_sizes\n","        ])\n","\n","        self.convs3 = nn.ModuleList([\n","            nn.Conv2d(1, 128, [window_size, 128], padding=(window_size - 1, 0))\n","            for window_size in window_sizes\n","        ])\n","        self.batchnorm128 = nn.BatchNorm2d(128)\n","        self.batchnorm64 = nn.BatchNorm2d(64)\n","        self.batchnorm32 = nn.BatchNorm2d(32)\n","        self.fc = nn.Linear(128 * len(window_sizes), 4)\n","\n","    def forward(self, x):\n","        x = torch.unsqueeze(x, 1)  # [B, 1, T, E] Add a channel dim.\n","        xs = []\n","        for conv1, conv2, conv3 in zip(self.convs1, self.convs2, self.convs3):\n","\n","            # print(x.shape)\n","            x2 = F.relu(conv1(x)) # [B, F, T, 1]\n","            x2 = self.batchnorm128(x2)\n","            # print(x2.permute(0, 3, 2, 1).shape)\n","\n","            x2 =  F.relu(conv2(x2.permute(0, 3, 2, 1)))\n","            x2 = self.batchnorm128(x2)\n","            # print(x2.shape)\n","\n","            x2 =  F.relu(conv3(x2.permute(0, 3, 2, 1)))\n","            x2 = self.batchnorm128(x2)\n","\n","            x2 = torch.squeeze(x2, -1)  # [B, F, T]\n","            x2 = F.max_pool1d(x2, x2.size(2))  # [B, F, 1]\n","            xs.append(x2)\n","            \n","        x = torch.cat(xs, 2)  # [B, F, window]\n","\n","\n","        # FC\n","        x = x.view(x.size(0), -1)  # [B, F * window]\n","        logits = self.fc(x)  # [B, class]\n","        probs = torch.sigmoid(logits) #.view(-1)\n","        return probs\n","\n","    def loss(self, probs, targets):\n","        return nn.CrossEntropyLoss()(probs.float(), targets.long())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fzRd5B11y8dQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622405670941,"user_tz":-180,"elapsed":433,"user":{"displayName":"Кирилл Тамогашев","photoUrl":"","userId":"04444979527243233763"}},"outputId":"71cb726a-74f0-4178-e86f-0fa232860840"},"source":["model = NewModel()\n","if device == torch.device('cuda'):\n","    model.cuda()\n","else:\n","    model.cpu()\n","model.train()\n","\n","optimizer = Adam(\n","    [p for p in model.parameters() if p.requires_grad], lr=1e-2, betas=(0.9, 0.999), eps=1e-5\n",")\n","\n","patience = 1000\n","best_loss = 1000\n","cnt = 0\n","BATCH_SIZE = 64\n","\n","model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NewModel(\n","  (convs1): ModuleList(\n","    (0): Conv2d(1, 128, kernel_size=[3, 128], stride=(1, 1), padding=(2, 0))\n","    (1): Conv2d(1, 128, kernel_size=[4, 128], stride=(1, 1), padding=(3, 0))\n","    (2): Conv2d(1, 128, kernel_size=[4, 128], stride=(1, 1), padding=(3, 0))\n","  )\n","  (convs2): ModuleList(\n","    (0): Conv2d(1, 128, kernel_size=[3, 128], stride=(1, 1), padding=(2, 0))\n","    (1): Conv2d(1, 128, kernel_size=[4, 128], stride=(1, 1), padding=(3, 0))\n","    (2): Conv2d(1, 128, kernel_size=[4, 128], stride=(1, 1), padding=(3, 0))\n","  )\n","  (convs3): ModuleList(\n","    (0): Conv2d(1, 128, kernel_size=[3, 128], stride=(1, 1), padding=(2, 0))\n","    (1): Conv2d(1, 128, kernel_size=[4, 128], stride=(1, 1), padding=(3, 0))\n","    (2): Conv2d(1, 128, kernel_size=[4, 128], stride=(1, 1), padding=(3, 0))\n","  )\n","  (batchnorm128): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (batchnorm64): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (batchnorm32): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc): Linear(in_features=384, out_features=4, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xmf8Epa2uq7G","executionInfo":{"status":"ok","timestamp":1622405677270,"user_tz":-180,"elapsed":197,"user":{"displayName":"Кирилл Тамогашев","photoUrl":"","userId":"04444979527243233763"}},"outputId":"8243e336-7e08-4043-c90e-6c0236ee1c65"},"source":["input, target = trainset.next_batch(64, device)\n","out = model(input)\n","model.loss(out, target).item()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.307113528251648"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":593,"referenced_widgets":["d4e0bd88bc824474a4efbcbb10b87319","dc91d82e92744fa5959cba673a8000fc","03e96ed9d9df4575bb57a429ad4e5d5b","32e91f01718443d3891be6486168643b","fd9b8c62ab0c42d9b4dd6d0ed206efc0","e6ce1fd210b84d63bcc81636535b76d7","96636997635e48e3b3ec69ae2e3dbabf","01e29c3dd59b4709b7266f378538b7b5"]},"id":"i1_KrgXW3Y9-","executionInfo":{"status":"ok","timestamp":1622405792999,"user_tz":-180,"elapsed":114180,"user":{"displayName":"Кирилл Тамогашев","photoUrl":"","userId":"04444979527243233763"}},"outputId":"7f0435ef-f15c-4fec-d87e-bdceceb184bb"},"source":["from tqdm.notebook  import tqdm\n","import torch as t\n","\n","\n","for i in tqdm(range(1000)):\n","\n","    optimizer.zero_grad()\n","\n","    input, target = trainset.next_batch(BATCH_SIZE, device=device)\n","    out = model(input)\n","    loss = model.loss(out, target)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if i % 100 == 0:\n","        model.eval()\n","\n","        with torch.no_grad():\n","            optimizer.zero_grad()\n","\n","            input, target = validset.next_batch(BATCH_SIZE, device=device)\n","            out = model(input)\n","            valid_loss = model.loss(out, target)\n","            out, target = out.cpu().detach(), target.cpu().detach()\n","\n","            pred_class = torch.argmax(out, axis=1)\n","            print(f'accuracy_score:{accuracy_score(pred_class, target.long())}')\n","            print(\"i {}, valid {}\".format(i, valid_loss.item()))\n","            print(\"_________\")\n","\n","        model.train()\n","\n","    if i % 1000 == 0 and best_loss > valid_loss.item():\n","        best_loss = valid_loss.item()\n","        cnt = 0\n","    else:\n","        cnt += 1\n","\n","    if cnt > patience:\n","        break\n","print('training finished')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d4e0bd88bc824474a4efbcbb10b87319","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["accuracy_score:0.4\n","i 0, valid 1.34881591796875\n","_________\n","accuracy_score:0.5576923076923077\n","i 100, valid 1.1859757900238037\n","_________\n","accuracy_score:0.4642857142857143\n","i 200, valid 1.279382348060608\n","_________\n","accuracy_score:0.4426229508196721\n","i 300, valid 1.3010450601577759\n","_________\n","accuracy_score:0.48214285714285715\n","i 400, valid 1.2615251541137695\n","_________\n","accuracy_score:0.39285714285714285\n","i 500, valid 1.3508108854293823\n","_________\n","accuracy_score:0.37037037037037035\n","i 600, valid 1.3732976913452148\n","_________\n","accuracy_score:0.45098039215686275\n","i 700, valid 1.2926876544952393\n","_________\n","accuracy_score:0.5\n","i 800, valid 1.2436679601669312\n","_________\n","accuracy_score:0.4444444444444444\n","i 900, valid 1.29922354221344\n","_________\n","\n","training finished\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dZ6npnAO9Abq","executionInfo":{"status":"ok","timestamp":1622405838971,"user_tz":-180,"elapsed":2521,"user":{"displayName":"Кирилл Тамогашев","photoUrl":"","userId":"04444979527243233763"}},"outputId":"ccc61e9e-8ac2-4aa7-98be-2f7e3063ecf5"},"source":["model.eval()\n","\n","with torch.no_grad():\n","    optimizer.zero_grad()\n","    acc_list = []\n","    for _ in range(20):\n","        input, target = testset.next_batch(BATCH_SIZE, device=device)\n","        out = model(input)\n","        valid_loss = model.loss(out, target)\n","        out, target = out.cpu().detach(), target.cpu().detach()\n","\n","        pred_class = torch.argmax(out, axis=1)\n","        score = accuracy_score(pred_class, target.long())\n","        acc_list.append(score)\n","print('Mean accuracy score {:.3}'.format(np.mean(acc_list)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mean accuracy score 0.447\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HCUuxjKbzWew"},"source":["Качество очень сильно упало, это связано с тем, что очень мало данных, и у модели не получается выучить закономерности, следовательно, она подгоняется под обучающую выборку."]},{"cell_type":"markdown","metadata":{"id":"gMVfN9-Y5uja"},"source":["Попробуем теперь сократить количество параметров и вернуться к 3 классам."]},{"cell_type":"code","metadata":{"id":"HgjibbQ65t7v"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class NewModel(nn.Module):\n","    def __init__(self, window_sizes=(4, 5)):\n","        super(NewModel, self).__init__()\n","\n","        self.convs1 = nn.ModuleList([\n","            nn.Conv2d(1, 128, [window_size, 128], padding=(window_size - 1, 0))\n","            for window_size in window_sizes\n","        ])\n","\n","        self.batchnorm128 = nn.BatchNorm2d(128)\n","\n","        self.fc = nn.Linear(128 * len(window_sizes), 3)\n","\n","    def forward(self, x):\n","        x = torch.unsqueeze(x, 1)  # [B, 1, T, E] Add a channel dim.\n","        xs = []\n","        for conv1 in self.convs1:\n","\n","            # print(x.shape)\n","            x2 = F.relu(conv1(x)) # [B, F, T, 1]\n","            x2 = self.batchnorm128(x2)\n","\n","\n","            x2 = torch.squeeze(x2, -1)  # [B, F, T]\n","            x2 = F.max_pool1d(x2, x2.size(2))  # [B, F, 1]\n","            xs.append(x2)\n","            \n","        x = torch.cat(xs, 2)  # [B, F, window]\n","\n","\n","        # FC\n","        x = x.view(x.size(0), -1)  # [B, F * window]\n","        logits = self.fc(x)  # [B, class]\n","        probs = torch.sigmoid(logits) #.view(-1)\n","        return probs\n","\n","    def loss(self, probs, targets):\n","        return nn.CrossEntropyLoss()(probs.float(), targets.long())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nVhBk4-UBEiC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622406647288,"user_tz":-180,"elapsed":413,"user":{"displayName":"Кирилл Тамогашев","photoUrl":"","userId":"04444979527243233763"}},"outputId":"2c3750f4-eeed-4995-9071-7a82a8907861"},"source":["patience = 1000\n","best_loss = 1000\n","cnt = 0\n","BATCH_SIZE = 64\n","\n","model = NewModel()\n","if device == torch.device('cuda'):\n","    model.cuda()\n","else:\n","    model.cpu()\n","model.train()\n","\n","model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NewModel(\n","  (convs1): ModuleList(\n","    (0): Conv2d(1, 128, kernel_size=[4, 128], stride=(1, 1), padding=(3, 0))\n","    (1): Conv2d(1, 128, kernel_size=[5, 128], stride=(1, 1), padding=(4, 0))\n","  )\n","  (batchnorm128): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc): Linear(in_features=256, out_features=3, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":111}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":491,"referenced_widgets":["abb690c9602c41ca885fb0690b6c64ac","2827e057c7a0417d9540ddc9774fdaec","15d40502a48b4d36bffc779ef8407d88","72e775b2e1f84ed297f028c43b29b9b7","ae52c24d1efa415ba76fdbe6eb3a2064","8f66589297d34c3cbcaf6620dd02fad9","1b5917171abe41d18facf723c8d38d0d","11d946060b1e494aacba6ec540353d28"]},"id":"IrfMpoys6LBR","executionInfo":{"status":"ok","timestamp":1622407064268,"user_tz":-180,"elapsed":93212,"user":{"displayName":"Кирилл Тамогашев","photoUrl":"","userId":"04444979527243233763"}},"outputId":"f3c65701-d1b8-41f7-c595-1acd7e5b004a"},"source":["from tqdm.notebook  import tqdm\n","import torch as t\n","\n","\n","optimizer = Adam(\n","    [p for p in model.parameters() if p.requires_grad], lr=1e-2, betas=(0.9, 0.999), eps=1e-5\n",")\n","\n","\n","for i in tqdm(range(800)):\n","\n","    optimizer.zero_grad()\n","\n","    input, target = trainset.next_batch(BATCH_SIZE, device=device)\n","    out = model(input)\n","    loss = model.loss(out, target)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if i % 100 == 0:\n","        model.eval()\n","\n","        with torch.no_grad():\n","            optimizer.zero_grad()\n","\n","            input, target = validset.next_batch(BATCH_SIZE, device=device)\n","            out = model(input)\n","            valid_loss = model.loss(out, target)\n","            out, target = out.cpu().detach(), target.cpu().detach()\n","\n","            pred_class = torch.argmax(out, axis=1)\n","            print(f'accuracy_score:{accuracy_score(pred_class, target.long())}')\n","            print(\"i {}, valid {}\".format(i, valid_loss.item()))\n","            print(\"_________\")\n","\n","        model.train()\n","\n","    if i % 1000 == 0 and best_loss > valid_loss.item():\n","        best_loss = valid_loss.item()\n","        cnt = 0\n","    else:\n","        cnt += 1\n","\n","    if cnt > patience:\n","        break\n","print('training finished')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"abb690c9602c41ca885fb0690b6c64ac","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=800.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["accuracy_score:0.6792452830188679\n","i 0, valid 0.8721995949745178\n","_________\n","accuracy_score:0.660377358490566\n","i 100, valid 0.8910675048828125\n","_________\n","accuracy_score:0.7272727272727273\n","i 200, valid 0.8241721391677856\n","_________\n","accuracy_score:0.66\n","i 300, valid 0.8914449214935303\n","_________\n","accuracy_score:0.6862745098039216\n","i 400, valid 0.865170419216156\n","_________\n","accuracy_score:0.64\n","i 500, valid 0.9114448428153992\n","_________\n","accuracy_score:0.7241379310344828\n","i 600, valid 0.8273069858551025\n","_________\n","accuracy_score:0.6938775510204082\n","i 700, valid 0.857567310333252\n","_________\n","\n","training finished\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MldfYDWQ_d9_","executionInfo":{"status":"ok","timestamp":1622407079360,"user_tz":-180,"elapsed":2509,"user":{"displayName":"Кирилл Тамогашев","photoUrl":"","userId":"04444979527243233763"}},"outputId":"e30a6c60-b21d-4bb3-e5ce-7694fcd0453f"},"source":["model.eval()\n","\n","with torch.no_grad():\n","    optimizer.zero_grad()\n","    acc_list = []\n","    for _ in range(20):\n","        input, target = testset.next_batch(BATCH_SIZE, device=device)\n","        out = model(input)\n","        valid_loss = model.loss(out, target)\n","        out, target = out.cpu().detach(), target.cpu().detach()\n","\n","        pred_class = torch.argmax(out, axis=1)\n","        score = accuracy_score(pred_class, target.long())\n","        acc_list.append(score)\n","print('Mean accuracy score {:.3}'.format(np.mean(acc_list)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mean accuracy score 0.725\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eX-L37g3-vne"},"source":["Нам удалось повысить качество, однако не очень значительно.\n","\n","**Общий вывод**: Умньшение параметров дает прирост, но очень незначительный. Как можно видеть, на существующих данных очень сложно повысить качество. Из-за препроцессинга мы вынуждены откинуть значимую долю данных, это уменшает возможность точно натренировать сетку. Деление данных на большее количество категорий и усложнение сетки не дает прирост, тк можнль начинает переобучатся. В такой ситуации меньшее количестов параметров лучше – модель с меньшей вероятностью переобучается.\n","\n","Классификация по возрасту может быть эффективна, например, в случае звонков в службу спасения или службу психологической помощи. Тогда имелась бы возможность подбирать специлиста напрямую адекватно возрасту, что повышает эффективность ответа на обращение."]}]}